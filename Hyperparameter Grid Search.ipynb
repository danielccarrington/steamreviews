{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96e6967-f268-427b-ab58-c943ddf6feab",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Steam Reviews (Grid Search)\n",
    "\n",
    "This file contains a modified version of [Sentiment Analysis of Steam Reviews.ipynb](<Sentiment Analysis of Steam Reviews.ipynb>), which has been used to execute a grid search for the model's hyperparameters. However, the code is distributed into larger functions and therefore is harder to document in finer detail. For a better explanation of the model, please see the original [Sentiment Analysis of Steam Reviews.ipynb](<Sentiment Analysis of Steam Reviews.ipynb>) version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f614e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext; torchtext.disable_torchtext_deprecation_warning()\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b147928-ebf2-4a4f-97cd-97ba37149438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 15\n",
    "batch_size_options = [256, 512, 1024]\n",
    "max_tokens_options = [64, 128, 256, 512]\n",
    "filter_size_options = [[3, 3], [3, 5], [3, 7], [5, 3], [5, 5], [5, 7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac5c1e96-1f14-4f4f-8b84-963ce8bd428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Setting the random seed has been moved further down to where the grid \n",
    "# search is performed to ensure that the seeds are reset with every loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e79a031-e822-438d-bb1b-9235b55b1eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select GPU if possible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e89f2f3-3e98-430f-93da-9be2eb904a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_setup(batch_size, max_tokens):\n",
    "\n",
    "    # Define a function to create a partial dataset\n",
    "    def create_partial_dataset(nrows=1000, override=True):\n",
    "        \n",
    "        dataset_path = 'data/dataset_' + str(nrows) + '.csv'\n",
    "        if (os.path.exists(dataset_path) and not override):\n",
    "            return dataset_path\n",
    "        \n",
    "        # Load the full dataset\n",
    "        # Location: https://www.kaggle.com/datasets/andrewmvd/steam-reviews\n",
    "        df = pd.read_csv('data/dataset.csv')\n",
    "        print(df.shape)\n",
    "    \n",
    "        # Make a partial dataset for exploration composed \n",
    "        # of 50% positive and 50% negative reviews.\n",
    "        df = df.groupby('review_score').sample(n=int(nrows/2), random_state=14).sort_index()\n",
    "    \n",
    "        # Export to CSV\n",
    "        df.to_csv(dataset_path)\n",
    "    \n",
    "        return dataset_path\n",
    "\n",
    "    # Disable dataset progress bars\n",
    "    datasets.utils.logging.disable_progress_bar() \n",
    "    \n",
    "    # Create a partial dataset for exploration\n",
    "    dataset_nrows = 10000\n",
    "    dataset_path = create_partial_dataset(dataset_nrows, override=False)\n",
    "    \n",
    "    # Load the Steam reviews dataset\n",
    "    full_data = datasets.load_dataset('csv', data_files=dataset_path, split='all')\n",
    "    \n",
    "    # Define a function to apply preprocessing fixes to the text\n",
    "    def preprocessing_text(row):\n",
    "    \n",
    "        # Make the text lower case\n",
    "        # Remove multiple space chars\n",
    "        row['text'] = row['text'].lower()\n",
    "        row['text'] = ' '.join(row['text'].split()).strip()\n",
    "        return row\n",
    "    \n",
    "    # Define a function to apply preprocessing fixes to the labels\n",
    "    def preprocessing_labels(row):\n",
    "    \n",
    "        # Alter the -1 (negative) label to be 0\n",
    "        if (row['label'] == -1):\n",
    "            row['label'] = 0\n",
    "        return row\n",
    "    \n",
    "    # Remove unnecessary columns\n",
    "    full_data = full_data.remove_columns(['Unnamed: 0', 'app_id', 'app_name', 'review_votes'])\n",
    "    \n",
    "    # Rename the columns to be generic\n",
    "    full_data = full_data.rename_column('review_text', 'text')\n",
    "    full_data = full_data.rename_column('review_score', 'label')\n",
    "    \n",
    "    # Remove entries that contain no text\n",
    "    full_data = full_data.filter(lambda row: row['text'] is not None)\n",
    "    \n",
    "    # Apply preprocessing fixes to the data\n",
    "    full_data = full_data.map(preprocessing_text)\n",
    "    full_data = full_data.map(preprocessing_labels)\n",
    "    \n",
    "    # Define the function that will split the sentences into tokens\n",
    "    def tokenize(row, max_tokens):\n",
    "        tokenizer = get_tokenizer('basic_english')\n",
    "        tokens = tokenizer(row['text'])[:max_tokens]\n",
    "        return {'tokens': tokens}\n",
    "    \n",
    "    # Split the text into tokens\n",
    "    full_data = full_data.map(\n",
    "        tokenize, fn_kwargs={'max_tokens': max_tokens}\n",
    "    )\n",
    "    \n",
    "    # Define a mapping of string tokens to integer values\n",
    "    vocab = build_vocab_from_iterator(\n",
    "        full_data['tokens'],\n",
    "        min_freq=5,\n",
    "        specials=['<unk>', '<pad>'],\n",
    "    )\n",
    "    vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "    # Store the index of the padding token\n",
    "    pad_index = vocab['<pad>']\n",
    "    \n",
    "    # Define the function that replaces string tokens with integer values\n",
    "    def numericalize(row, vocab):\n",
    "        tokens = vocab.lookup_indices(row['tokens'])\n",
    "        return {'tokens': tokens}\n",
    "    \n",
    "    # Replace the string tokens with integer values\n",
    "    full_data = full_data.map(numericalize, fn_kwargs={'vocab': vocab})\n",
    "    full_data = full_data.with_format(type='torch', columns=['tokens', 'label'])\n",
    "    \n",
    "    # Define the the function for collating and batching the data\n",
    "    def collate_fn(pad_index):\n",
    "        def collate_fn(batch):\n",
    "            batch_tokens = [i['tokens'] for i in batch]\n",
    "            batch_tokens = nn.utils.rnn.pad_sequence(\n",
    "                batch_tokens, padding_value=pad_index, batch_first=True\n",
    "            )\n",
    "            batch_label = [i['label'] for i in batch]\n",
    "            batch_label = torch.stack(batch_label)\n",
    "            batch = {'tokens': batch_tokens, 'label': batch_label}\n",
    "            return batch\n",
    "    \n",
    "        return collate_fn\n",
    "    \n",
    "    # Split the dataset into training/validation and test sets\n",
    "    full_data = full_data.train_test_split(test_size=0.2)\n",
    "    train_valid_data = full_data['train']\n",
    "    test_data = full_data['test']\n",
    "    \n",
    "    # Further split the training set into training and validation sets\n",
    "    train_valid_data = train_valid_data.train_test_split(test_size=0.25)\n",
    "    train_data = train_valid_data['train']\n",
    "    valid_data = train_valid_data['test']\n",
    "\n",
    "    # Calculate the number of unique labels\n",
    "    unique_labels = len(train_data.unique('label'))\n",
    "        \n",
    "    # Create the data loaders for training section\n",
    "    train_data_loader = DataLoader(train_data, batch_size, collate_fn=collate_fn(pad_index), shuffle=True)\n",
    "    valid_data_loader = DataLoader(valid_data, batch_size, collate_fn=collate_fn(pad_index))\n",
    "    test_data_loader = DataLoader(test_data, batch_size, collate_fn=collate_fn(pad_index))\n",
    "\n",
    "    return train_data_loader, valid_data_loader, test_data_loader, vocab, unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b86530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the convolutional neural network\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    # Define the function for initliasing the CNN model\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim, # The size of each embedding vector\n",
    "        filters, # Number of filters\n",
    "        filter_size, # The size of the filters\n",
    "        max_tokens, # Max tokens\n",
    "        vocab, # Dictionary of embeddings\n",
    "        output_dim, # No. of unique labels\n",
    "        pad_index, # The index of the pad, which will get defaulted to all zeros\n",
    "        device # Run on the CPU or GPU\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Store for later use\n",
    "        self.vocab = vocab\n",
    "        self.device = device\n",
    "     \n",
    "        # Lookup table that stores embeddings\n",
    "        num_embeddings = len(vocab)\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim, padding_idx=pad_index)\n",
    "        \n",
    "        # Convolution layers\n",
    "        # Embedding vector size, Number of filters, Filter/Kernel size\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, filters, filter_size[0], padding='same')\n",
    "        self.conv2 = nn.Conv1d(embedding_dim, filters, filter_size[1], padding='same')\n",
    "        \n",
    "        # Linear layer\n",
    "        # No. of convolution layers * Earlier output channels, No. of unique labels\n",
    "        self.fc1 = nn.Linear(2 * filters, output_dim)\n",
    "\n",
    "        # Define the loss function and optimiser\n",
    "        # Cross-entropy loss and Adaptive Moment Estimation\n",
    "        self.criterion = nn.CrossEntropyLoss().to(self.device)\n",
    "        self.optimizer = optim.Adam(self.parameters())\n",
    "\n",
    "    # Define the function to return the total model parameters\n",
    "    def total_parameters(self):\n",
    "    \n",
    "        # Compute the total number of parameters\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "    # Define the function to process a pass through the CNN\n",
    "    def forward(self, tokens):\n",
    "\n",
    "        # Tokens\n",
    "        # Size: [Batch size, Max tokens]\n",
    "        # Example: [512, 256]\n",
    "\n",
    "        # Token embeddings\n",
    "        # Size: [Batch size, Max tokens, Embedding vector size]\n",
    "        # Example: [512, 256, 300]\n",
    "        embedded = self.embedding(tokens)\n",
    "\n",
    "        # Re-arrange the token embeddings\n",
    "        # Size: [Batch size, Embedding vector size, Max tokens]\n",
    "        # Example: [512, 300, 256]\n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "\n",
    "        # First convolutional layer plus ReLU activation\n",
    "        # Size: [Batch size, Output channels, Max tokens - Filter size + 1]\n",
    "        # Example: [512, 100, 254]\n",
    "        conved1 = torch.relu(self.conv1(embedded))\n",
    "\n",
    "        # Second convolutional layer plus ReLU activation\n",
    "        # Size: [Batch size, Output channels, Max tokens - Filter size + 1]\n",
    "        # Example: [512, 100, 254]\n",
    "        conved2 = torch.relu(self.conv2(embedded))    \n",
    "\n",
    "        # First max pool layer\n",
    "        # Size: [Batch size, Output channels]\n",
    "        # Example: [512, 100]\n",
    "        pooled1 = conved1.max(dim=-1).values\n",
    "\n",
    "        # Second max pool layer\n",
    "        # Size: [Batch size, Output channels]\n",
    "        # Example: [512, 100]\n",
    "        pooled2 = conved1.max(dim=-1).values\n",
    "        \n",
    "        # Concatenate the tensors returned by the pooled layers\n",
    "        # Size: [Batch size, 2*Output channels]\n",
    "        # Example: [512, 200]\n",
    "        cat = torch.cat([pooled1, pooled2], dim=-1)\n",
    "        \n",
    "        # Linear layer\n",
    "        # Size: [Batch size, No. of unique labels]\n",
    "        # Example: [512, 2]\n",
    "        prediction = self.fc1(cat)      \n",
    "        return prediction\n",
    "\n",
    "    # Define the function to train the model\n",
    "    def train(self, train_loader):\n",
    "    \n",
    "        # Loop through every batch in the training data\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        for batch in train_loader:\n",
    "    \n",
    "            # Send the data to the GPU\n",
    "            tokens, labels = batch['tokens'].to(self.device), batch['label'].to(self.device)\n",
    "    \n",
    "            # Zero the parameter gradients\n",
    "            self.optimizer.zero_grad()\n",
    "    \n",
    "            # Forward + backward + optimize\n",
    "            predictions = self(tokens)\n",
    "            loss = self.criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "    \n",
    "            # Calculate the running loss and accuracy\n",
    "            running_loss += loss.item()\n",
    "            running_accuracy += get_accuracy(predictions, labels).item()\n",
    "            \n",
    "        return (running_loss / len(train_loader), \n",
    "               running_accuracy / len(train_loader))\n",
    "\n",
    "    # Define the function to evaluate the model\n",
    "    def evaluate(self, test_loader):\n",
    "    \n",
    "        # Loop through every batch in the test data\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "    \n",
    "                # Send the data to the GPU\n",
    "                tokens, labels = batch['tokens'].to(self.device), batch['label'].to(self.device)\n",
    "    \n",
    "                # Evaluate the predicted label\n",
    "                predictions = self(tokens)\n",
    "                loss = self.criterion(predictions, labels)\n",
    "        \n",
    "                # Calculate the running loss and accuracy\n",
    "                running_loss += loss.item()\n",
    "                running_accuracy += get_accuracy(predictions, labels).item()\n",
    "    \n",
    "        return (running_loss / len(test_loader), \n",
    "               running_accuracy / len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9fec677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to initialise a model\n",
    "def create_cnn_model(filter_size, max_tokens, vocab, unique_labels, pad_index, device):\n",
    "\n",
    "    # Note: The embedding vector size has to remain at 300 in order to match \n",
    "    # that returned by GloVe. It can be changed if the usage of GloVe is removed.\n",
    "    \n",
    "    # Model inputs\n",
    "    embedding_dim = 300\n",
    "    filters = 100\n",
    "\n",
    "    # Initialise the model\n",
    "    model = CNN(\n",
    "        embedding_dim, # The size of each embedding vector\n",
    "        filters, # Number of filters  \n",
    "        filter_size, # The size of the filters\n",
    "        max_tokens, # Max tokens\n",
    "        vocab, # Dictionary of embeddings\n",
    "        unique_labels, # No. of unique labels\n",
    "        pad_index, # The index of the pad, which will get defaulted to all zeros\n",
    "        device # Run on the CPU or GPU\n",
    "    )\n",
    "    \n",
    "    # Use starting weights from GloVe\n",
    "    # https://nlp.stanford.edu/projects/glove/\n",
    "    vectors = torchtext.vocab.GloVe(dim=embedding_dim)\n",
    "    model.embedding.weight.data = vectors.get_vecs_by_tokens(vocab.get_itos())\n",
    "    \n",
    "    # Move the model to the GPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62efdd11-e1e2-43e8-b005-cbf82015a053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the accuracy of the predictions\n",
    "def get_accuracy(prediction, label):\n",
    "    predicted_classes = prediction.argmax(dim=-1)\n",
    "    correct_predictions = predicted_classes.eq(label).sum()\n",
    "    accuracy = correct_predictions / len(prediction)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d036b96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HP: 256-64-[3, 3] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.453486 | Training Time: 14.47s\n",
      "HP: 256-64-[3, 5] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.45827 | Training Time: 16.02s\n",
      "HP: 256-64-[3, 7] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.461844 | Training Time: 15.73s\n",
      "HP: 256-64-[5, 3] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.459697 | Training Time: 16.89s\n",
      "HP: 256-64-[5, 5] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.454064 | Training Time: 15.88s\n",
      "HP: 256-64-[5, 7] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.455731 | Training Time: 16.59s\n",
      "HP: 256-128-[3, 3] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.436439 | Training Time: 18.46s\n",
      "HP: 256-128-[3, 5] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.436563 | Training Time: 19.68s\n",
      "HP: 256-128-[3, 7] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.438674 | Training Time: 19.82s\n",
      "HP: 256-128-[5, 3] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.441436 | Training Time: 20.03s\n",
      "HP: 256-128-[5, 5] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.433358 | Training Time: 19.5s\n",
      "HP: 256-128-[5, 7] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.441405 | Training Time: 17.95s\n",
      "HP: 512-64-[3, 3] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.457036 | Training Time: 14.67s\n",
      "HP: 512-64-[3, 5] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.464191 | Training Time: 14.71s\n",
      "HP: 512-64-[3, 7] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.457052 | Training Time: 14.99s\n",
      "HP: 512-64-[5, 3] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.465861 | Training Time: 15.2s\n",
      "HP: 512-64-[5, 5] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.455914 | Training Time: 15.2s\n",
      "HP: 512-64-[5, 7] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.458071 | Training Time: 14.96s\n",
      "HP: 512-128-[3, 3] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.437575 | Training Time: 18.16s\n",
      "HP: 512-128-[3, 5] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.438999 | Training Time: 19.34s\n",
      "HP: 512-128-[3, 7] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.43746 | Training Time: 17.71s\n",
      "HP: 512-128-[5, 3] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.436956 | Training Time: 16.52s\n",
      "HP: 512-128-[5, 5] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.438116 | Training Time: 16.0s\n",
      "HP: 512-128-[5, 7] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.434985 | Training Time: 16.07s\n",
      "HP: 512-256-[3, 3] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.417407 | Training Time: 22.59s\n",
      "HP: 512-256-[3, 5] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.423766 | Training Time: 25.38s\n",
      "HP: 512-256-[3, 7] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.41924 | Training Time: 25.73s\n",
      "HP: 512-256-[5, 3] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.423366 | Training Time: 29.27s\n",
      "HP: 512-256-[5, 5] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.427804 | Training Time: 32.71s\n",
      "HP: 512-256-[5, 7] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.430561 | Training Time: 32.97s\n",
      "HP: 1024-64-[3, 3] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.456032 | Training Time: 12.72s\n",
      "HP: 1024-64-[3, 5] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.464885 | Training Time: 12.4s\n",
      "HP: 1024-64-[3, 7] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.459319 | Training Time: 11.99s\n",
      "HP: 1024-64-[5, 3] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.466506 | Training Time: 12.28s\n",
      "HP: 1024-64-[5, 5] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.458162 | Training Time: 12.76s\n",
      "HP: 1024-64-[5, 7] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.457323 | Training Time: 12.47s\n",
      "HP: 1024-128-[3, 3] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.439711 | Training Time: 15.07s\n",
      "HP: 1024-128-[3, 5] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.442232 | Training Time: 14.92s\n",
      "HP: 1024-128-[3, 7] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.440204 | Training Time: 14.98s\n",
      "HP: 1024-128-[5, 3] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.442674 | Training Time: 15.11s\n",
      "HP: 1024-128-[5, 5] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.440742 | Training Time: 15.55s\n",
      "HP: 1024-128-[5, 7] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.439106 | Training Time: 15.61s\n",
      "HP: 1024-256-[3, 3] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.420851 | Training Time: 21.99s\n",
      "HP: 1024-256-[3, 5] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.428819 | Training Time: 24.87s\n",
      "HP: 1024-256-[3, 7] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.420664 | Training Time: 24.79s\n",
      "HP: 1024-256-[5, 3] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.428208 | Training Time: 29.32s\n",
      "HP: 1024-256-[5, 5] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.429588 | Training Time: 31.78s\n",
      "HP: 1024-256-[5, 7] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.430659 | Training Time: 32.13s\n",
      "HP: 1024-512-[3, 3] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.420068 | Training Time: 38.47s\n",
      "HP: 1024-512-[3, 5] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.421508 | Training Time: 41.8s\n",
      "HP: 1024-512-[3, 7] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.413981 | Training Time: 41.98s\n",
      "HP: 1024-512-[5, 3] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.422161 | Training Time: 73.1s\n",
      "HP: 1024-512-[5, 5] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.426629 | Training Time: 73.41s\n",
      "HP: 1024-512-[5, 7] | Epoch: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 | Validation (Loss): 0.425879 | Training Time: 72.35s\n",
      "\n",
      "Total Exploration Time: 1245.01s\n"
     ]
    }
   ],
   "source": [
    "# Results storage\n",
    "total_time = 0\n",
    "best_valid_loss_all_runs = float('inf')\n",
    "best_model_state = {}\n",
    "results = {\n",
    "    'Batch Size':[], 'Max Tokens': [], \n",
    "    'Filter Size':[], 'Epoch': [], \n",
    "    'Training (Loss)': [], 'Training (Accuracy)': [], \n",
    "    'Validation (Loss)': [], 'Validation (Accuracy)': [], \n",
    "    'Testing (Loss)': [], 'Testing (Accuracy)': []\n",
    "}\n",
    "\n",
    "# Loop through hyperparameter options\n",
    "for batch_size in batch_size_options:\n",
    "    for max_tokens in max_tokens_options:\n",
    "        for filter_size in filter_size_options:\n",
    "\n",
    "            # Set the random seed for deterministic behaviour\n",
    "            seed = 14\n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            torch.cuda.manual_seed(seed)\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "\n",
    "            # Only run if the max tokens are larger than the batch size\n",
    "            if max_tokens >= batch_size:\n",
    "                continue\n",
    "            \n",
    "            # Results storage\n",
    "            best_train_loss = float('inf')\n",
    "            best_train_acc = float('inf')\n",
    "            best_valid_loss = float('inf')\n",
    "            best_valid_acc = float('inf')\n",
    "            best_epoch = 0\n",
    "\n",
    "            # Short description of hyperparameters for feedback\n",
    "            hyperparameter_desc = str(batch_size)+'-'+str(max_tokens)+'-'+str(filter_size) \n",
    "            \n",
    "            # Setup the data\n",
    "            train_data_loader, valid_data_loader, test_data_loader, vocab, unique_labels = data_setup(batch_size, max_tokens)\n",
    "        \n",
    "            # Store the index of the padding token\n",
    "            pad_index = vocab['<pad>']\n",
    "            \n",
    "            # Create the model\n",
    "            model = create_cnn_model(filter_size, max_tokens, vocab, unique_labels, pad_index, device)\n",
    "            \n",
    "            # Run the required number of epochs\n",
    "            start = time.time()\n",
    "            print('HP:', hyperparameter_desc, end=' | ')\n",
    "            print('Epoch: ', end='')\n",
    "            for epoch in range(1, epochs+1):\n",
    "            \n",
    "                # Run the model\n",
    "                print(epoch, end=' ')\n",
    "                train_loss, train_acc = model.train(train_data_loader)\n",
    "                valid_loss, valid_acc = model.evaluate(valid_data_loader)\n",
    "            \n",
    "                # Save the best set of weightings within the epoch\n",
    "                if valid_loss < best_valid_loss:\n",
    "                    torch.save(model.state_dict(), 'checkpoints/cnn_grid_search.pt')\n",
    "                    best_train_loss = train_loss\n",
    "                    best_train_acc = train_acc\n",
    "                    best_valid_loss = valid_loss\n",
    "                    best_valid_acc = valid_acc\n",
    "                    best_epoch = epoch\n",
    "\n",
    "                # Save the best set of weights across all runs\n",
    "                if valid_loss < best_valid_loss_all_runs:\n",
    "                    best_valid_loss_all_runs = valid_loss\n",
    "                    best_model_state = model.state_dict()\n",
    "\n",
    "            # Load the best set of weighting within the epoch\n",
    "            model.load_state_dict(torch.load('checkpoints/cnn_grid_search.pt'))\n",
    "\n",
    "            # Compute the testing loss and accuracy\n",
    "            test_loss, test_acc = model.evaluate(test_data_loader)\n",
    "        \n",
    "            # Store the results of the run\n",
    "            results['Batch Size'].append(batch_size)\n",
    "            results['Max Tokens'].append(max_tokens)\n",
    "            results['Filter Size'].append(filter_size)\n",
    "            results['Epoch'].append(best_epoch)\n",
    "            results['Training (Loss)'].append(best_train_loss)\n",
    "            results['Training (Accuracy)'].append(best_train_acc)\n",
    "            results['Validation (Loss)'].append(best_valid_loss)\n",
    "            results['Validation (Accuracy)'].append(best_valid_acc)\n",
    "            results['Testing (Loss)'].append(test_loss)\n",
    "            results['Testing (Accuracy)'].append(test_acc)\n",
    "            \n",
    "            # Print the training time\n",
    "            end = time.time()\n",
    "            total_time += end-start\n",
    "            print('| Validation (Loss):', str(np.round(best_valid_loss, 6)), end=' ')\n",
    "            print('| Training Time:', str(np.round(end-start, 2))+'s')\n",
    "\n",
    "# Save the best weighting across all runs\n",
    "torch.save(best_model_state, 'checkpoints/cnn_grid_search.pt')\n",
    "\n",
    "print('\\nTotal Exploration Time:', str(np.round(total_time, 2))+'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fc41db6-575b-4e91-98dc-65377667b69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_c07ef\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_c07ef_level0_col0\" class=\"col_heading level0 col0\" >Batch Size</th>\n",
       "      <th id=\"T_c07ef_level0_col1\" class=\"col_heading level0 col1\" >Max Tokens</th>\n",
       "      <th id=\"T_c07ef_level0_col2\" class=\"col_heading level0 col2\" >Filter Size</th>\n",
       "      <th id=\"T_c07ef_level0_col3\" class=\"col_heading level0 col3\" >Epoch</th>\n",
       "      <th id=\"T_c07ef_level0_col4\" class=\"col_heading level0 col4\" >Training (Loss)</th>\n",
       "      <th id=\"T_c07ef_level0_col5\" class=\"col_heading level0 col5\" >Training (Accuracy)</th>\n",
       "      <th id=\"T_c07ef_level0_col6\" class=\"col_heading level0 col6\" >Validation (Loss)</th>\n",
       "      <th id=\"T_c07ef_level0_col7\" class=\"col_heading level0 col7\" >Validation (Accuracy)</th>\n",
       "      <th id=\"T_c07ef_level0_col8\" class=\"col_heading level0 col8\" >Testing (Loss)</th>\n",
       "      <th id=\"T_c07ef_level0_col9\" class=\"col_heading level0 col9\" >Testing (Accuracy)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row0_col0\" class=\"data row0 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row0_col1\" class=\"data row0 col1\" >512</td>\n",
       "      <td id=\"T_c07ef_row0_col2\" class=\"data row0 col2\" >[3, 7]</td>\n",
       "      <td id=\"T_c07ef_row0_col3\" class=\"data row0 col3\" >12</td>\n",
       "      <td id=\"T_c07ef_row0_col4\" class=\"data row0 col4\" >0.263356</td>\n",
       "      <td id=\"T_c07ef_row0_col5\" class=\"data row0 col5\" >0.871315</td>\n",
       "      <td id=\"T_c07ef_row0_col6\" class=\"data row0 col6\" >0.413981</td>\n",
       "      <td id=\"T_c07ef_row0_col7\" class=\"data row0 col7\" >0.789345</td>\n",
       "      <td id=\"T_c07ef_row0_col8\" class=\"data row0 col8\" >0.430199</td>\n",
       "      <td id=\"T_c07ef_row0_col9\" class=\"data row0 col9\" >0.792425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row1_col0\" class=\"data row1 col0\" >512</td>\n",
       "      <td id=\"T_c07ef_row1_col1\" class=\"data row1 col1\" >256</td>\n",
       "      <td id=\"T_c07ef_row1_col2\" class=\"data row1 col2\" >[3, 3]</td>\n",
       "      <td id=\"T_c07ef_row1_col3\" class=\"data row1 col3\" >7</td>\n",
       "      <td id=\"T_c07ef_row1_col4\" class=\"data row1 col4\" >0.286710</td>\n",
       "      <td id=\"T_c07ef_row1_col5\" class=\"data row1 col5\" >0.861777</td>\n",
       "      <td id=\"T_c07ef_row1_col6\" class=\"data row1 col6\" >0.417407</td>\n",
       "      <td id=\"T_c07ef_row1_col7\" class=\"data row1 col7\" >0.782301</td>\n",
       "      <td id=\"T_c07ef_row1_col8\" class=\"data row1 col8\" >0.431387</td>\n",
       "      <td id=\"T_c07ef_row1_col9\" class=\"data row1 col9\" >0.794389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row2_col0\" class=\"data row2 col0\" >512</td>\n",
       "      <td id=\"T_c07ef_row2_col1\" class=\"data row2 col1\" >256</td>\n",
       "      <td id=\"T_c07ef_row2_col2\" class=\"data row2 col2\" >[3, 7]</td>\n",
       "      <td id=\"T_c07ef_row2_col3\" class=\"data row2 col3\" >7</td>\n",
       "      <td id=\"T_c07ef_row2_col4\" class=\"data row2 col4\" >0.294314</td>\n",
       "      <td id=\"T_c07ef_row2_col5\" class=\"data row2 col5\" >0.856717</td>\n",
       "      <td id=\"T_c07ef_row2_col6\" class=\"data row2 col6\" >0.419240</td>\n",
       "      <td id=\"T_c07ef_row2_col7\" class=\"data row2 col7\" >0.783000</td>\n",
       "      <td id=\"T_c07ef_row2_col8\" class=\"data row2 col8\" >0.431800</td>\n",
       "      <td id=\"T_c07ef_row2_col9\" class=\"data row2 col9\" >0.794231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row3_col0\" class=\"data row3 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row3_col1\" class=\"data row3 col1\" >512</td>\n",
       "      <td id=\"T_c07ef_row3_col2\" class=\"data row3 col2\" >[3, 3]</td>\n",
       "      <td id=\"T_c07ef_row3_col3\" class=\"data row3 col3\" >12</td>\n",
       "      <td id=\"T_c07ef_row3_col4\" class=\"data row3 col4\" >0.270199</td>\n",
       "      <td id=\"T_c07ef_row3_col5\" class=\"data row3 col5\" >0.868266</td>\n",
       "      <td id=\"T_c07ef_row3_col6\" class=\"data row3 col6\" >0.420068</td>\n",
       "      <td id=\"T_c07ef_row3_col7\" class=\"data row3 col7\" >0.782334</td>\n",
       "      <td id=\"T_c07ef_row3_col8\" class=\"data row3 col8\" >0.435397</td>\n",
       "      <td id=\"T_c07ef_row3_col9\" class=\"data row3 col9\" >0.787417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row4_col0\" class=\"data row4 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row4_col1\" class=\"data row4 col1\" >256</td>\n",
       "      <td id=\"T_c07ef_row4_col2\" class=\"data row4 col2\" >[3, 7]</td>\n",
       "      <td id=\"T_c07ef_row4_col3\" class=\"data row4 col3\" >11</td>\n",
       "      <td id=\"T_c07ef_row4_col4\" class=\"data row4 col4\" >0.284882</td>\n",
       "      <td id=\"T_c07ef_row4_col5\" class=\"data row4 col5\" >0.869581</td>\n",
       "      <td id=\"T_c07ef_row4_col6\" class=\"data row4 col6\" >0.420664</td>\n",
       "      <td id=\"T_c07ef_row4_col7\" class=\"data row4 col7\" >0.780331</td>\n",
       "      <td id=\"T_c07ef_row4_col8\" class=\"data row4 col8\" >0.433918</td>\n",
       "      <td id=\"T_c07ef_row4_col9\" class=\"data row4 col9\" >0.791862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row5_col0\" class=\"data row5 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row5_col1\" class=\"data row5 col1\" >256</td>\n",
       "      <td id=\"T_c07ef_row5_col2\" class=\"data row5 col2\" >[3, 3]</td>\n",
       "      <td id=\"T_c07ef_row5_col3\" class=\"data row5 col3\" >12</td>\n",
       "      <td id=\"T_c07ef_row5_col4\" class=\"data row5 col4\" >0.264852</td>\n",
       "      <td id=\"T_c07ef_row5_col5\" class=\"data row5 col5\" >0.871290</td>\n",
       "      <td id=\"T_c07ef_row5_col6\" class=\"data row5 col6\" >0.420851</td>\n",
       "      <td id=\"T_c07ef_row5_col7\" class=\"data row5 col7\" >0.773419</td>\n",
       "      <td id=\"T_c07ef_row5_col8\" class=\"data row5 col8\" >0.437200</td>\n",
       "      <td id=\"T_c07ef_row5_col9\" class=\"data row5 col9\" >0.783110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row6_col0\" class=\"data row6 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row6_col1\" class=\"data row6 col1\" >512</td>\n",
       "      <td id=\"T_c07ef_row6_col2\" class=\"data row6 col2\" >[3, 5]</td>\n",
       "      <td id=\"T_c07ef_row6_col3\" class=\"data row6 col3\" >12</td>\n",
       "      <td id=\"T_c07ef_row6_col4\" class=\"data row6 col4\" >0.274947</td>\n",
       "      <td id=\"T_c07ef_row6_col5\" class=\"data row6 col5\" >0.863903</td>\n",
       "      <td id=\"T_c07ef_row6_col6\" class=\"data row6 col6\" >0.421508</td>\n",
       "      <td id=\"T_c07ef_row6_col7\" class=\"data row6 col7\" >0.780381</td>\n",
       "      <td id=\"T_c07ef_row6_col8\" class=\"data row6 col8\" >0.435257</td>\n",
       "      <td id=\"T_c07ef_row6_col9\" class=\"data row6 col9\" >0.789808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row7_col0\" class=\"data row7 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row7_col1\" class=\"data row7 col1\" >512</td>\n",
       "      <td id=\"T_c07ef_row7_col2\" class=\"data row7 col2\" >[5, 3]</td>\n",
       "      <td id=\"T_c07ef_row7_col3\" class=\"data row7 col3\" >10</td>\n",
       "      <td id=\"T_c07ef_row7_col4\" class=\"data row7 col4\" >0.272684</td>\n",
       "      <td id=\"T_c07ef_row7_col5\" class=\"data row7 col5\" >0.869568</td>\n",
       "      <td id=\"T_c07ef_row7_col6\" class=\"data row7 col6\" >0.422161</td>\n",
       "      <td id=\"T_c07ef_row7_col7\" class=\"data row7 col7\" >0.781821</td>\n",
       "      <td id=\"T_c07ef_row7_col8\" class=\"data row7 col8\" >0.437378</td>\n",
       "      <td id=\"T_c07ef_row7_col9\" class=\"data row7 col9\" >0.783511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row8_col0\" class=\"data row8 col0\" >512</td>\n",
       "      <td id=\"T_c07ef_row8_col1\" class=\"data row8 col1\" >256</td>\n",
       "      <td id=\"T_c07ef_row8_col2\" class=\"data row8 col2\" >[5, 3]</td>\n",
       "      <td id=\"T_c07ef_row8_col3\" class=\"data row8 col3\" >7</td>\n",
       "      <td id=\"T_c07ef_row8_col4\" class=\"data row8 col4\" >0.262334</td>\n",
       "      <td id=\"T_c07ef_row8_col5\" class=\"data row8 col5\" >0.872818</td>\n",
       "      <td id=\"T_c07ef_row8_col6\" class=\"data row8 col6\" >0.423366</td>\n",
       "      <td id=\"T_c07ef_row8_col7\" class=\"data row8 col7\" >0.781918</td>\n",
       "      <td id=\"T_c07ef_row8_col8\" class=\"data row8 col8\" >0.432806</td>\n",
       "      <td id=\"T_c07ef_row8_col9\" class=\"data row8 col9\" >0.790272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row9_col0\" class=\"data row9 col0\" >512</td>\n",
       "      <td id=\"T_c07ef_row9_col1\" class=\"data row9 col1\" >256</td>\n",
       "      <td id=\"T_c07ef_row9_col2\" class=\"data row9 col2\" >[3, 5]</td>\n",
       "      <td id=\"T_c07ef_row9_col3\" class=\"data row9 col3\" >7</td>\n",
       "      <td id=\"T_c07ef_row9_col4\" class=\"data row9 col4\" >0.284502</td>\n",
       "      <td id=\"T_c07ef_row9_col5\" class=\"data row9 col5\" >0.863420</td>\n",
       "      <td id=\"T_c07ef_row9_col6\" class=\"data row9 col6\" >0.423766</td>\n",
       "      <td id=\"T_c07ef_row9_col7\" class=\"data row9 col7\" >0.784412</td>\n",
       "      <td id=\"T_c07ef_row9_col8\" class=\"data row9 col8\" >0.431039</td>\n",
       "      <td id=\"T_c07ef_row9_col9\" class=\"data row9 col9\" >0.787289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row10_col0\" class=\"data row10 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row10_col1\" class=\"data row10 col1\" >512</td>\n",
       "      <td id=\"T_c07ef_row10_col2\" class=\"data row10 col2\" >[5, 7]</td>\n",
       "      <td id=\"T_c07ef_row10_col3\" class=\"data row10 col3\" >11</td>\n",
       "      <td id=\"T_c07ef_row10_col4\" class=\"data row10 col4\" >0.264342</td>\n",
       "      <td id=\"T_c07ef_row10_col5\" class=\"data row10 col5\" >0.873891</td>\n",
       "      <td id=\"T_c07ef_row10_col6\" class=\"data row10 col6\" >0.425879</td>\n",
       "      <td id=\"T_c07ef_row10_col7\" class=\"data row10 col7\" >0.779892</td>\n",
       "      <td id=\"T_c07ef_row10_col8\" class=\"data row10 col8\" >0.437476</td>\n",
       "      <td id=\"T_c07ef_row10_col9\" class=\"data row10 col9\" >0.787054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row11_col0\" class=\"data row11 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row11_col1\" class=\"data row11 col1\" >512</td>\n",
       "      <td id=\"T_c07ef_row11_col2\" class=\"data row11 col2\" >[5, 5]</td>\n",
       "      <td id=\"T_c07ef_row11_col3\" class=\"data row11 col3\" >9</td>\n",
       "      <td id=\"T_c07ef_row11_col4\" class=\"data row11 col4\" >0.285752</td>\n",
       "      <td id=\"T_c07ef_row11_col5\" class=\"data row11 col5\" >0.858410</td>\n",
       "      <td id=\"T_c07ef_row11_col6\" class=\"data row11 col6\" >0.426629</td>\n",
       "      <td id=\"T_c07ef_row11_col7\" class=\"data row11 col7\" >0.780331</td>\n",
       "      <td id=\"T_c07ef_row11_col8\" class=\"data row11 col8\" >0.432091</td>\n",
       "      <td id=\"T_c07ef_row11_col9\" class=\"data row11 col9\" >0.785026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row12_col0\" class=\"data row12 col0\" >512</td>\n",
       "      <td id=\"T_c07ef_row12_col1\" class=\"data row12 col1\" >256</td>\n",
       "      <td id=\"T_c07ef_row12_col2\" class=\"data row12 col2\" >[5, 5]</td>\n",
       "      <td id=\"T_c07ef_row12_col3\" class=\"data row12 col3\" >6</td>\n",
       "      <td id=\"T_c07ef_row12_col4\" class=\"data row12 col4\" >0.296010</td>\n",
       "      <td id=\"T_c07ef_row12_col5\" class=\"data row12 col5\" >0.860312</td>\n",
       "      <td id=\"T_c07ef_row12_col6\" class=\"data row12 col6\" >0.427804</td>\n",
       "      <td id=\"T_c07ef_row12_col7\" class=\"data row12 col7\" >0.779212</td>\n",
       "      <td id=\"T_c07ef_row12_col8\" class=\"data row12 col8\" >0.434301</td>\n",
       "      <td id=\"T_c07ef_row12_col9\" class=\"data row12 col9\" >0.790166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row13_col0\" class=\"data row13 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row13_col1\" class=\"data row13 col1\" >256</td>\n",
       "      <td id=\"T_c07ef_row13_col2\" class=\"data row13 col2\" >[5, 3]</td>\n",
       "      <td id=\"T_c07ef_row13_col3\" class=\"data row13 col3\" >9</td>\n",
       "      <td id=\"T_c07ef_row13_col4\" class=\"data row13 col4\" >0.291188</td>\n",
       "      <td id=\"T_c07ef_row13_col5\" class=\"data row13 col5\" >0.854413</td>\n",
       "      <td id=\"T_c07ef_row13_col6\" class=\"data row13 col6\" >0.428208</td>\n",
       "      <td id=\"T_c07ef_row13_col7\" class=\"data row13 col7\" >0.776837</td>\n",
       "      <td id=\"T_c07ef_row13_col8\" class=\"data row13 col8\" >0.437072</td>\n",
       "      <td id=\"T_c07ef_row13_col9\" class=\"data row13 col9\" >0.787568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row14_col0\" class=\"data row14 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row14_col1\" class=\"data row14 col1\" >256</td>\n",
       "      <td id=\"T_c07ef_row14_col2\" class=\"data row14 col2\" >[3, 5]</td>\n",
       "      <td id=\"T_c07ef_row14_col3\" class=\"data row14 col3\" >10</td>\n",
       "      <td id=\"T_c07ef_row14_col4\" class=\"data row14 col4\" >0.290780</td>\n",
       "      <td id=\"T_c07ef_row14_col5\" class=\"data row14 col5\" >0.858723</td>\n",
       "      <td id=\"T_c07ef_row14_col6\" class=\"data row14 col6\" >0.428819</td>\n",
       "      <td id=\"T_c07ef_row14_col7\" class=\"data row14 col7\" >0.766771</td>\n",
       "      <td id=\"T_c07ef_row14_col8\" class=\"data row14 col8\" >0.433729</td>\n",
       "      <td id=\"T_c07ef_row14_col9\" class=\"data row14 col9\" >0.779128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row15_col0\" class=\"data row15 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row15_col1\" class=\"data row15 col1\" >256</td>\n",
       "      <td id=\"T_c07ef_row15_col2\" class=\"data row15 col2\" >[5, 5]</td>\n",
       "      <td id=\"T_c07ef_row15_col3\" class=\"data row15 col3\" >11</td>\n",
       "      <td id=\"T_c07ef_row15_col4\" class=\"data row15 col4\" >0.260744</td>\n",
       "      <td id=\"T_c07ef_row15_col5\" class=\"data row15 col5\" >0.878573</td>\n",
       "      <td id=\"T_c07ef_row15_col6\" class=\"data row15 col6\" >0.429588</td>\n",
       "      <td id=\"T_c07ef_row15_col7\" class=\"data row15 col7\" >0.778690</td>\n",
       "      <td id=\"T_c07ef_row15_col8\" class=\"data row15 col8\" >0.439478</td>\n",
       "      <td id=\"T_c07ef_row15_col9\" class=\"data row15 col9\" >0.788006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row16_col0\" class=\"data row16 col0\" >512</td>\n",
       "      <td id=\"T_c07ef_row16_col1\" class=\"data row16 col1\" >256</td>\n",
       "      <td id=\"T_c07ef_row16_col2\" class=\"data row16 col2\" >[5, 7]</td>\n",
       "      <td id=\"T_c07ef_row16_col3\" class=\"data row16 col3\" >5</td>\n",
       "      <td id=\"T_c07ef_row16_col4\" class=\"data row16 col4\" >0.346190</td>\n",
       "      <td id=\"T_c07ef_row16_col5\" class=\"data row16 col5\" >0.832246</td>\n",
       "      <td id=\"T_c07ef_row16_col6\" class=\"data row16 col6\" >0.430561</td>\n",
       "      <td id=\"T_c07ef_row16_col7\" class=\"data row16 col7\" >0.775517</td>\n",
       "      <td id=\"T_c07ef_row16_col8\" class=\"data row16 col8\" >0.439131</td>\n",
       "      <td id=\"T_c07ef_row16_col9\" class=\"data row16 col9\" >0.780136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row17_col0\" class=\"data row17 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row17_col1\" class=\"data row17 col1\" >256</td>\n",
       "      <td id=\"T_c07ef_row17_col2\" class=\"data row17 col2\" >[5, 7]</td>\n",
       "      <td id=\"T_c07ef_row17_col3\" class=\"data row17 col3\" >10</td>\n",
       "      <td id=\"T_c07ef_row17_col4\" class=\"data row17 col4\" >0.290283</td>\n",
       "      <td id=\"T_c07ef_row17_col5\" class=\"data row17 col5\" >0.861268</td>\n",
       "      <td id=\"T_c07ef_row17_col6\" class=\"data row17 col6\" >0.430659</td>\n",
       "      <td id=\"T_c07ef_row17_col7\" class=\"data row17 col7\" >0.771341</td>\n",
       "      <td id=\"T_c07ef_row17_col8\" class=\"data row17 col8\" >0.442262</td>\n",
       "      <td id=\"T_c07ef_row17_col9\" class=\"data row17 col9\" >0.778478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row18_col0\" class=\"data row18 col0\" >256</td>\n",
       "      <td id=\"T_c07ef_row18_col1\" class=\"data row18 col1\" >128</td>\n",
       "      <td id=\"T_c07ef_row18_col2\" class=\"data row18 col2\" >[5, 5]</td>\n",
       "      <td id=\"T_c07ef_row18_col3\" class=\"data row18 col3\" >4</td>\n",
       "      <td id=\"T_c07ef_row18_col4\" class=\"data row18 col4\" >0.329431</td>\n",
       "      <td id=\"T_c07ef_row18_col5\" class=\"data row18 col5\" >0.836333</td>\n",
       "      <td id=\"T_c07ef_row18_col6\" class=\"data row18 col6\" >0.433358</td>\n",
       "      <td id=\"T_c07ef_row18_col7\" class=\"data row18 col7\" >0.764464</td>\n",
       "      <td id=\"T_c07ef_row18_col8\" class=\"data row18 col8\" >0.437652</td>\n",
       "      <td id=\"T_c07ef_row18_col9\" class=\"data row18 col9\" >0.770294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row19_col0\" class=\"data row19 col0\" >512</td>\n",
       "      <td id=\"T_c07ef_row19_col1\" class=\"data row19 col1\" >128</td>\n",
       "      <td id=\"T_c07ef_row19_col2\" class=\"data row19 col2\" >[5, 7]</td>\n",
       "      <td id=\"T_c07ef_row19_col3\" class=\"data row19 col3\" >6</td>\n",
       "      <td id=\"T_c07ef_row19_col4\" class=\"data row19 col4\" >0.303670</td>\n",
       "      <td id=\"T_c07ef_row19_col5\" class=\"data row19 col5\" >0.852704</td>\n",
       "      <td id=\"T_c07ef_row19_col6\" class=\"data row19 col6\" >0.434985</td>\n",
       "      <td id=\"T_c07ef_row19_col7\" class=\"data row19 col7\" >0.778830</td>\n",
       "      <td id=\"T_c07ef_row19_col8\" class=\"data row19 col8\" >0.434540</td>\n",
       "      <td id=\"T_c07ef_row19_col9\" class=\"data row19 col9\" >0.782683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row20_col0\" class=\"data row20 col0\" >256</td>\n",
       "      <td id=\"T_c07ef_row20_col1\" class=\"data row20 col1\" >128</td>\n",
       "      <td id=\"T_c07ef_row20_col2\" class=\"data row20 col2\" >[3, 3]</td>\n",
       "      <td id=\"T_c07ef_row20_col3\" class=\"data row20 col3\" >5</td>\n",
       "      <td id=\"T_c07ef_row20_col4\" class=\"data row20 col4\" >0.293056</td>\n",
       "      <td id=\"T_c07ef_row20_col5\" class=\"data row20 col5\" >0.858468</td>\n",
       "      <td id=\"T_c07ef_row20_col6\" class=\"data row20 col6\" >0.436439</td>\n",
       "      <td id=\"T_c07ef_row20_col7\" class=\"data row20 col7\" >0.782132</td>\n",
       "      <td id=\"T_c07ef_row20_col8\" class=\"data row20 col8\" >0.442439</td>\n",
       "      <td id=\"T_c07ef_row20_col9\" class=\"data row20 col9\" >0.786659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row21_col0\" class=\"data row21 col0\" >256</td>\n",
       "      <td id=\"T_c07ef_row21_col1\" class=\"data row21 col1\" >128</td>\n",
       "      <td id=\"T_c07ef_row21_col2\" class=\"data row21 col2\" >[3, 5]</td>\n",
       "      <td id=\"T_c07ef_row21_col3\" class=\"data row21 col3\" >5</td>\n",
       "      <td id=\"T_c07ef_row21_col4\" class=\"data row21 col4\" >0.307357</td>\n",
       "      <td id=\"T_c07ef_row21_col5\" class=\"data row21 col5\" >0.847309</td>\n",
       "      <td id=\"T_c07ef_row21_col6\" class=\"data row21 col6\" >0.436563</td>\n",
       "      <td id=\"T_c07ef_row21_col7\" class=\"data row21 col7\" >0.774571</td>\n",
       "      <td id=\"T_c07ef_row21_col8\" class=\"data row21 col8\" >0.435129</td>\n",
       "      <td id=\"T_c07ef_row21_col9\" class=\"data row21 col9\" >0.787029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row22_col0\" class=\"data row22 col0\" >512</td>\n",
       "      <td id=\"T_c07ef_row22_col1\" class=\"data row22 col1\" >128</td>\n",
       "      <td id=\"T_c07ef_row22_col2\" class=\"data row22 col2\" >[5, 3]</td>\n",
       "      <td id=\"T_c07ef_row22_col3\" class=\"data row22 col3\" >6</td>\n",
       "      <td id=\"T_c07ef_row22_col4\" class=\"data row22 col4\" >0.297972</td>\n",
       "      <td id=\"T_c07ef_row22_col5\" class=\"data row22 col5\" >0.857031</td>\n",
       "      <td id=\"T_c07ef_row22_col6\" class=\"data row22 col6\" >0.436956</td>\n",
       "      <td id=\"T_c07ef_row22_col7\" class=\"data row22 col7\" >0.779912</td>\n",
       "      <td id=\"T_c07ef_row22_col8\" class=\"data row22 col8\" >0.438895</td>\n",
       "      <td id=\"T_c07ef_row22_col9\" class=\"data row22 col9\" >0.782142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row23_col0\" class=\"data row23 col0\" >512</td>\n",
       "      <td id=\"T_c07ef_row23_col1\" class=\"data row23 col1\" >128</td>\n",
       "      <td id=\"T_c07ef_row23_col2\" class=\"data row23 col2\" >[3, 7]</td>\n",
       "      <td id=\"T_c07ef_row23_col3\" class=\"data row23 col3\" >7</td>\n",
       "      <td id=\"T_c07ef_row23_col4\" class=\"data row23 col4\" >0.293122</td>\n",
       "      <td id=\"T_c07ef_row23_col5\" class=\"data row23 col5\" >0.852659</td>\n",
       "      <td id=\"T_c07ef_row23_col6\" class=\"data row23 col6\" >0.437460</td>\n",
       "      <td id=\"T_c07ef_row23_col7\" class=\"data row23 col7\" >0.765118</td>\n",
       "      <td id=\"T_c07ef_row23_col8\" class=\"data row23 col8\" >0.434056</td>\n",
       "      <td id=\"T_c07ef_row23_col9\" class=\"data row23 col9\" >0.775966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row24_col0\" class=\"data row24 col0\" >512</td>\n",
       "      <td id=\"T_c07ef_row24_col1\" class=\"data row24 col1\" >128</td>\n",
       "      <td id=\"T_c07ef_row24_col2\" class=\"data row24 col2\" >[3, 3]</td>\n",
       "      <td id=\"T_c07ef_row24_col3\" class=\"data row24 col3\" >6</td>\n",
       "      <td id=\"T_c07ef_row24_col4\" class=\"data row24 col4\" >0.331986</td>\n",
       "      <td id=\"T_c07ef_row24_col5\" class=\"data row24 col5\" >0.837825</td>\n",
       "      <td id=\"T_c07ef_row24_col6\" class=\"data row24 col6\" >0.437575</td>\n",
       "      <td id=\"T_c07ef_row24_col7\" class=\"data row24 col7\" >0.771558</td>\n",
       "      <td id=\"T_c07ef_row24_col8\" class=\"data row24 col8\" >0.436223</td>\n",
       "      <td id=\"T_c07ef_row24_col9\" class=\"data row24 col9\" >0.783224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row25_col0\" class=\"data row25 col0\" >512</td>\n",
       "      <td id=\"T_c07ef_row25_col1\" class=\"data row25 col1\" >128</td>\n",
       "      <td id=\"T_c07ef_row25_col2\" class=\"data row25 col2\" >[5, 5]</td>\n",
       "      <td id=\"T_c07ef_row25_col3\" class=\"data row25 col3\" >6</td>\n",
       "      <td id=\"T_c07ef_row25_col4\" class=\"data row25 col4\" >0.304189</td>\n",
       "      <td id=\"T_c07ef_row25_col5\" class=\"data row25 col5\" >0.847626</td>\n",
       "      <td id=\"T_c07ef_row25_col6\" class=\"data row25 col6\" >0.438116</td>\n",
       "      <td id=\"T_c07ef_row25_col7\" class=\"data row25 col7\" >0.763759</td>\n",
       "      <td id=\"T_c07ef_row25_col8\" class=\"data row25 col8\" >0.440783</td>\n",
       "      <td id=\"T_c07ef_row25_col9\" class=\"data row25 col9\" >0.767071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row26_col0\" class=\"data row26 col0\" >256</td>\n",
       "      <td id=\"T_c07ef_row26_col1\" class=\"data row26 col1\" >128</td>\n",
       "      <td id=\"T_c07ef_row26_col2\" class=\"data row26 col2\" >[3, 7]</td>\n",
       "      <td id=\"T_c07ef_row26_col3\" class=\"data row26 col3\" >4</td>\n",
       "      <td id=\"T_c07ef_row26_col4\" class=\"data row26 col4\" >0.353501</td>\n",
       "      <td id=\"T_c07ef_row26_col5\" class=\"data row26 col5\" >0.825357</td>\n",
       "      <td id=\"T_c07ef_row26_col6\" class=\"data row26 col6\" >0.438674</td>\n",
       "      <td id=\"T_c07ef_row26_col7\" class=\"data row26 col7\" >0.765322</td>\n",
       "      <td id=\"T_c07ef_row26_col8\" class=\"data row26 col8\" >0.435899</td>\n",
       "      <td id=\"T_c07ef_row26_col9\" class=\"data row26 col9\" >0.769067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row27_col0\" class=\"data row27 col0\" >512</td>\n",
       "      <td id=\"T_c07ef_row27_col1\" class=\"data row27 col1\" >128</td>\n",
       "      <td id=\"T_c07ef_row27_col2\" class=\"data row27 col2\" >[3, 5]</td>\n",
       "      <td id=\"T_c07ef_row27_col3\" class=\"data row27 col3\" >7</td>\n",
       "      <td id=\"T_c07ef_row27_col4\" class=\"data row27 col4\" >0.298636</td>\n",
       "      <td id=\"T_c07ef_row27_col5\" class=\"data row27 col5\" >0.855581</td>\n",
       "      <td id=\"T_c07ef_row27_col6\" class=\"data row27 col6\" >0.438999</td>\n",
       "      <td id=\"T_c07ef_row27_col7\" class=\"data row27 col7\" >0.771123</td>\n",
       "      <td id=\"T_c07ef_row27_col8\" class=\"data row27 col8\" >0.437557</td>\n",
       "      <td id=\"T_c07ef_row27_col9\" class=\"data row27 col9\" >0.783660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row28_col0\" class=\"data row28 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row28_col1\" class=\"data row28 col1\" >128</td>\n",
       "      <td id=\"T_c07ef_row28_col2\" class=\"data row28 col2\" >[5, 7]</td>\n",
       "      <td id=\"T_c07ef_row28_col3\" class=\"data row28 col3\" >9</td>\n",
       "      <td id=\"T_c07ef_row28_col4\" class=\"data row28 col4\" >0.295054</td>\n",
       "      <td id=\"T_c07ef_row28_col5\" class=\"data row28 col5\" >0.863086</td>\n",
       "      <td id=\"T_c07ef_row28_col6\" class=\"data row28 col6\" >0.439106</td>\n",
       "      <td id=\"T_c07ef_row28_col7\" class=\"data row28 col7\" >0.763203</td>\n",
       "      <td id=\"T_c07ef_row28_col8\" class=\"data row28 col8\" >0.438243</td>\n",
       "      <td id=\"T_c07ef_row28_col9\" class=\"data row28 col9\" >0.766308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row29_col0\" class=\"data row29 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row29_col1\" class=\"data row29 col1\" >128</td>\n",
       "      <td id=\"T_c07ef_row29_col2\" class=\"data row29 col2\" >[3, 3]</td>\n",
       "      <td id=\"T_c07ef_row29_col3\" class=\"data row29 col3\" >10</td>\n",
       "      <td id=\"T_c07ef_row29_col4\" class=\"data row29 col4\" >0.309038</td>\n",
       "      <td id=\"T_c07ef_row29_col5\" class=\"data row29 col5\" >0.848701</td>\n",
       "      <td id=\"T_c07ef_row29_col6\" class=\"data row29 col6\" >0.439711</td>\n",
       "      <td id=\"T_c07ef_row29_col7\" class=\"data row29 col7\" >0.763841</td>\n",
       "      <td id=\"T_c07ef_row29_col8\" class=\"data row29 col8\" >0.442195</td>\n",
       "      <td id=\"T_c07ef_row29_col9\" class=\"data row29 col9\" >0.774195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row30_col0\" class=\"data row30 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row30_col1\" class=\"data row30 col1\" >128</td>\n",
       "      <td id=\"T_c07ef_row30_col2\" class=\"data row30 col2\" >[3, 7]</td>\n",
       "      <td id=\"T_c07ef_row30_col3\" class=\"data row30 col3\" >11</td>\n",
       "      <td id=\"T_c07ef_row30_col4\" class=\"data row30 col4\" >0.297131</td>\n",
       "      <td id=\"T_c07ef_row30_col5\" class=\"data row30 col5\" >0.857837</td>\n",
       "      <td id=\"T_c07ef_row30_col6\" class=\"data row30 col6\" >0.440204</td>\n",
       "      <td id=\"T_c07ef_row30_col7\" class=\"data row30 col7\" >0.768111</td>\n",
       "      <td id=\"T_c07ef_row30_col8\" class=\"data row30 col8\" >0.437429</td>\n",
       "      <td id=\"T_c07ef_row30_col9\" class=\"data row30 col9\" >0.774170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row31_col0\" class=\"data row31 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row31_col1\" class=\"data row31 col1\" >128</td>\n",
       "      <td id=\"T_c07ef_row31_col2\" class=\"data row31 col2\" >[5, 5]</td>\n",
       "      <td id=\"T_c07ef_row31_col3\" class=\"data row31 col3\" >9</td>\n",
       "      <td id=\"T_c07ef_row31_col4\" class=\"data row31 col4\" >0.318395</td>\n",
       "      <td id=\"T_c07ef_row31_col5\" class=\"data row31 col5\" >0.844641</td>\n",
       "      <td id=\"T_c07ef_row31_col6\" class=\"data row31 col6\" >0.440742</td>\n",
       "      <td id=\"T_c07ef_row31_col7\" class=\"data row31 col7\" >0.771366</td>\n",
       "      <td id=\"T_c07ef_row31_col8\" class=\"data row31 col8\" >0.442200</td>\n",
       "      <td id=\"T_c07ef_row31_col9\" class=\"data row31 col9\" >0.775085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row32_col0\" class=\"data row32 col0\" >256</td>\n",
       "      <td id=\"T_c07ef_row32_col1\" class=\"data row32 col1\" >128</td>\n",
       "      <td id=\"T_c07ef_row32_col2\" class=\"data row32 col2\" >[5, 7]</td>\n",
       "      <td id=\"T_c07ef_row32_col3\" class=\"data row32 col3\" >5</td>\n",
       "      <td id=\"T_c07ef_row32_col4\" class=\"data row32 col4\" >0.283931</td>\n",
       "      <td id=\"T_c07ef_row32_col5\" class=\"data row32 col5\" >0.856789</td>\n",
       "      <td id=\"T_c07ef_row32_col6\" class=\"data row32 col6\" >0.441405</td>\n",
       "      <td id=\"T_c07ef_row32_col7\" class=\"data row32 col7\" >0.768237</td>\n",
       "      <td id=\"T_c07ef_row32_col8\" class=\"data row32 col8\" >0.436254</td>\n",
       "      <td id=\"T_c07ef_row32_col9\" class=\"data row32 col9\" >0.773594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row33_col0\" class=\"data row33 col0\" >256</td>\n",
       "      <td id=\"T_c07ef_row33_col1\" class=\"data row33 col1\" >128</td>\n",
       "      <td id=\"T_c07ef_row33_col2\" class=\"data row33 col2\" >[5, 3]</td>\n",
       "      <td id=\"T_c07ef_row33_col3\" class=\"data row33 col3\" >3</td>\n",
       "      <td id=\"T_c07ef_row33_col4\" class=\"data row33 col4\" >0.387612</td>\n",
       "      <td id=\"T_c07ef_row33_col5\" class=\"data row33 col5\" >0.805306</td>\n",
       "      <td id=\"T_c07ef_row33_col6\" class=\"data row33 col6\" >0.441436</td>\n",
       "      <td id=\"T_c07ef_row33_col7\" class=\"data row33 col7\" >0.759329</td>\n",
       "      <td id=\"T_c07ef_row33_col8\" class=\"data row33 col8\" >0.437067</td>\n",
       "      <td id=\"T_c07ef_row33_col9\" class=\"data row33 col9\" >0.765293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row34_col0\" class=\"data row34 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row34_col1\" class=\"data row34 col1\" >128</td>\n",
       "      <td id=\"T_c07ef_row34_col2\" class=\"data row34 col2\" >[3, 5]</td>\n",
       "      <td id=\"T_c07ef_row34_col3\" class=\"data row34 col3\" >12</td>\n",
       "      <td id=\"T_c07ef_row34_col4\" class=\"data row34 col4\" >0.269531</td>\n",
       "      <td id=\"T_c07ef_row34_col5\" class=\"data row34 col5\" >0.867189</td>\n",
       "      <td id=\"T_c07ef_row34_col6\" class=\"data row34 col6\" >0.442232</td>\n",
       "      <td id=\"T_c07ef_row34_col7\" class=\"data row34 col7\" >0.779817</td>\n",
       "      <td id=\"T_c07ef_row34_col8\" class=\"data row34 col8\" >0.443428</td>\n",
       "      <td id=\"T_c07ef_row34_col9\" class=\"data row34 col9\" >0.782484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row35_col0\" class=\"data row35 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row35_col1\" class=\"data row35 col1\" >128</td>\n",
       "      <td id=\"T_c07ef_row35_col2\" class=\"data row35 col2\" >[5, 3]</td>\n",
       "      <td id=\"T_c07ef_row35_col3\" class=\"data row35 col3\" >12</td>\n",
       "      <td id=\"T_c07ef_row35_col4\" class=\"data row35 col4\" >0.238974</td>\n",
       "      <td id=\"T_c07ef_row35_col5\" class=\"data row35 col5\" >0.888332</td>\n",
       "      <td id=\"T_c07ef_row35_col6\" class=\"data row35 col6\" >0.442674</td>\n",
       "      <td id=\"T_c07ef_row35_col7\" class=\"data row35 col7\" >0.769575</td>\n",
       "      <td id=\"T_c07ef_row35_col8\" class=\"data row35 col8\" >0.445555</td>\n",
       "      <td id=\"T_c07ef_row35_col9\" class=\"data row35 col9\" >0.774784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row36_col0\" class=\"data row36 col0\" >256</td>\n",
       "      <td id=\"T_c07ef_row36_col1\" class=\"data row36 col1\" >64</td>\n",
       "      <td id=\"T_c07ef_row36_col2\" class=\"data row36 col2\" >[3, 3]</td>\n",
       "      <td id=\"T_c07ef_row36_col3\" class=\"data row36 col3\" >5</td>\n",
       "      <td id=\"T_c07ef_row36_col4\" class=\"data row36 col4\" >0.322395</td>\n",
       "      <td id=\"T_c07ef_row36_col5\" class=\"data row36 col5\" >0.844623</td>\n",
       "      <td id=\"T_c07ef_row36_col6\" class=\"data row36 col6\" >0.453486</td>\n",
       "      <td id=\"T_c07ef_row36_col7\" class=\"data row36 col7\" >0.776509</td>\n",
       "      <td id=\"T_c07ef_row36_col8\" class=\"data row36 col8\" >0.458796</td>\n",
       "      <td id=\"T_c07ef_row36_col9\" class=\"data row36 col9\" >0.773001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row37_col0\" class=\"data row37 col0\" >256</td>\n",
       "      <td id=\"T_c07ef_row37_col1\" class=\"data row37 col1\" >64</td>\n",
       "      <td id=\"T_c07ef_row37_col2\" class=\"data row37 col2\" >[5, 5]</td>\n",
       "      <td id=\"T_c07ef_row37_col3\" class=\"data row37 col3\" >5</td>\n",
       "      <td id=\"T_c07ef_row37_col4\" class=\"data row37 col4\" >0.292009</td>\n",
       "      <td id=\"T_c07ef_row37_col5\" class=\"data row37 col5\" >0.860818</td>\n",
       "      <td id=\"T_c07ef_row37_col6\" class=\"data row37 col6\" >0.454064</td>\n",
       "      <td id=\"T_c07ef_row37_col7\" class=\"data row37 col7\" >0.776879</td>\n",
       "      <td id=\"T_c07ef_row37_col8\" class=\"data row37 col8\" >0.461782</td>\n",
       "      <td id=\"T_c07ef_row37_col9\" class=\"data row37 col9\" >0.773608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row38_col0\" class=\"data row38 col0\" >256</td>\n",
       "      <td id=\"T_c07ef_row38_col1\" class=\"data row38 col1\" >64</td>\n",
       "      <td id=\"T_c07ef_row38_col2\" class=\"data row38 col2\" >[5, 7]</td>\n",
       "      <td id=\"T_c07ef_row38_col3\" class=\"data row38 col3\" >4</td>\n",
       "      <td id=\"T_c07ef_row38_col4\" class=\"data row38 col4\" >0.335458</td>\n",
       "      <td id=\"T_c07ef_row38_col5\" class=\"data row38 col5\" >0.839354</td>\n",
       "      <td id=\"T_c07ef_row38_col6\" class=\"data row38 col6\" >0.455731</td>\n",
       "      <td id=\"T_c07ef_row38_col7\" class=\"data row38 col7\" >0.768593</td>\n",
       "      <td id=\"T_c07ef_row38_col8\" class=\"data row38 col8\" >0.455739</td>\n",
       "      <td id=\"T_c07ef_row38_col9\" class=\"data row38 col9\" >0.774836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row39_col0\" class=\"data row39 col0\" >512</td>\n",
       "      <td id=\"T_c07ef_row39_col1\" class=\"data row39 col1\" >64</td>\n",
       "      <td id=\"T_c07ef_row39_col2\" class=\"data row39 col2\" >[5, 5]</td>\n",
       "      <td id=\"T_c07ef_row39_col3\" class=\"data row39 col3\" >6</td>\n",
       "      <td id=\"T_c07ef_row39_col4\" class=\"data row39 col4\" >0.312347</td>\n",
       "      <td id=\"T_c07ef_row39_col5\" class=\"data row39 col5\" >0.851902</td>\n",
       "      <td id=\"T_c07ef_row39_col6\" class=\"data row39 col6\" >0.455914</td>\n",
       "      <td id=\"T_c07ef_row39_col7\" class=\"data row39 col7\" >0.760182</td>\n",
       "      <td id=\"T_c07ef_row39_col8\" class=\"data row39 col8\" >0.455475</td>\n",
       "      <td id=\"T_c07ef_row39_col9\" class=\"data row39 col9\" >0.766041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row40_col0\" class=\"data row40 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row40_col1\" class=\"data row40 col1\" >64</td>\n",
       "      <td id=\"T_c07ef_row40_col2\" class=\"data row40 col2\" >[3, 3]</td>\n",
       "      <td id=\"T_c07ef_row40_col3\" class=\"data row40 col3\" >11</td>\n",
       "      <td id=\"T_c07ef_row40_col4\" class=\"data row40 col4\" >0.313711</td>\n",
       "      <td id=\"T_c07ef_row40_col5\" class=\"data row40 col5\" >0.849940</td>\n",
       "      <td id=\"T_c07ef_row40_col6\" class=\"data row40 col6\" >0.456032</td>\n",
       "      <td id=\"T_c07ef_row40_col7\" class=\"data row40 col7\" >0.774859</td>\n",
       "      <td id=\"T_c07ef_row40_col8\" class=\"data row40 col8\" >0.462040</td>\n",
       "      <td id=\"T_c07ef_row40_col9\" class=\"data row40 col9\" >0.771617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row41_col0\" class=\"data row41 col0\" >512</td>\n",
       "      <td id=\"T_c07ef_row41_col1\" class=\"data row41 col1\" >64</td>\n",
       "      <td id=\"T_c07ef_row41_col2\" class=\"data row41 col2\" >[3, 3]</td>\n",
       "      <td id=\"T_c07ef_row41_col3\" class=\"data row41 col3\" >7</td>\n",
       "      <td id=\"T_c07ef_row41_col4\" class=\"data row41 col4\" >0.303185</td>\n",
       "      <td id=\"T_c07ef_row41_col5\" class=\"data row41 col5\" >0.849260</td>\n",
       "      <td id=\"T_c07ef_row41_col6\" class=\"data row41 col6\" >0.457036</td>\n",
       "      <td id=\"T_c07ef_row41_col7\" class=\"data row41 col7\" >0.773776</td>\n",
       "      <td id=\"T_c07ef_row41_col8\" class=\"data row41 col8\" >0.458953</td>\n",
       "      <td id=\"T_c07ef_row41_col9\" class=\"data row41 col9\" >0.776230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row42_col0\" class=\"data row42 col0\" >512</td>\n",
       "      <td id=\"T_c07ef_row42_col1\" class=\"data row42 col1\" >64</td>\n",
       "      <td id=\"T_c07ef_row42_col2\" class=\"data row42 col2\" >[3, 7]</td>\n",
       "      <td id=\"T_c07ef_row42_col3\" class=\"data row42 col3\" >6</td>\n",
       "      <td id=\"T_c07ef_row42_col4\" class=\"data row42 col4\" >0.359950</td>\n",
       "      <td id=\"T_c07ef_row42_col5\" class=\"data row42 col5\" >0.819702</td>\n",
       "      <td id=\"T_c07ef_row42_col6\" class=\"data row42 col6\" >0.457052</td>\n",
       "      <td id=\"T_c07ef_row42_col7\" class=\"data row42 col7\" >0.771400</td>\n",
       "      <td id=\"T_c07ef_row42_col8\" class=\"data row42 col8\" >0.458757</td>\n",
       "      <td id=\"T_c07ef_row42_col9\" class=\"data row42 col9\" >0.763653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row43_col0\" class=\"data row43 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row43_col1\" class=\"data row43 col1\" >64</td>\n",
       "      <td id=\"T_c07ef_row43_col2\" class=\"data row43 col2\" >[5, 7]</td>\n",
       "      <td id=\"T_c07ef_row43_col3\" class=\"data row43 col3\" >10</td>\n",
       "      <td id=\"T_c07ef_row43_col4\" class=\"data row43 col4\" >0.307301</td>\n",
       "      <td id=\"T_c07ef_row43_col5\" class=\"data row43 col5\" >0.848861</td>\n",
       "      <td id=\"T_c07ef_row43_col6\" class=\"data row43 col6\" >0.457323</td>\n",
       "      <td id=\"T_c07ef_row43_col7\" class=\"data row43 col7\" >0.759171</td>\n",
       "      <td id=\"T_c07ef_row43_col8\" class=\"data row43 col8\" >0.459585</td>\n",
       "      <td id=\"T_c07ef_row43_col9\" class=\"data row43 col9\" >0.759246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row44_col0\" class=\"data row44 col0\" >512</td>\n",
       "      <td id=\"T_c07ef_row44_col1\" class=\"data row44 col1\" >64</td>\n",
       "      <td id=\"T_c07ef_row44_col2\" class=\"data row44 col2\" >[5, 7]</td>\n",
       "      <td id=\"T_c07ef_row44_col3\" class=\"data row44 col3\" >5</td>\n",
       "      <td id=\"T_c07ef_row44_col4\" class=\"data row44 col4\" >0.358348</td>\n",
       "      <td id=\"T_c07ef_row44_col5\" class=\"data row44 col5\" >0.822057</td>\n",
       "      <td id=\"T_c07ef_row44_col6\" class=\"data row44 col6\" >0.458071</td>\n",
       "      <td id=\"T_c07ef_row44_col7\" class=\"data row44 col7\" >0.764735</td>\n",
       "      <td id=\"T_c07ef_row44_col8\" class=\"data row44 col8\" >0.459186</td>\n",
       "      <td id=\"T_c07ef_row44_col9\" class=\"data row44 col9\" >0.768589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row45_col0\" class=\"data row45 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row45_col1\" class=\"data row45 col1\" >64</td>\n",
       "      <td id=\"T_c07ef_row45_col2\" class=\"data row45 col2\" >[5, 5]</td>\n",
       "      <td id=\"T_c07ef_row45_col3\" class=\"data row45 col3\" >10</td>\n",
       "      <td id=\"T_c07ef_row45_col4\" class=\"data row45 col4\" >0.297850</td>\n",
       "      <td id=\"T_c07ef_row45_col5\" class=\"data row45 col5\" >0.858247</td>\n",
       "      <td id=\"T_c07ef_row45_col6\" class=\"data row45 col6\" >0.458162</td>\n",
       "      <td id=\"T_c07ef_row45_col7\" class=\"data row45 col7\" >0.772167</td>\n",
       "      <td id=\"T_c07ef_row45_col8\" class=\"data row45 col8\" >0.460060</td>\n",
       "      <td id=\"T_c07ef_row45_col9\" class=\"data row45 col9\" >0.770690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row46_col0\" class=\"data row46 col0\" >256</td>\n",
       "      <td id=\"T_c07ef_row46_col1\" class=\"data row46 col1\" >64</td>\n",
       "      <td id=\"T_c07ef_row46_col2\" class=\"data row46 col2\" >[3, 5]</td>\n",
       "      <td id=\"T_c07ef_row46_col3\" class=\"data row46 col3\" >4</td>\n",
       "      <td id=\"T_c07ef_row46_col4\" class=\"data row46 col4\" >0.373509</td>\n",
       "      <td id=\"T_c07ef_row46_col5\" class=\"data row46 col5\" >0.809121</td>\n",
       "      <td id=\"T_c07ef_row46_col6\" class=\"data row46 col6\" >0.458270</td>\n",
       "      <td id=\"T_c07ef_row46_col7\" class=\"data row46 col7\" >0.761387</td>\n",
       "      <td id=\"T_c07ef_row46_col8\" class=\"data row46 col8\" >0.454756</td>\n",
       "      <td id=\"T_c07ef_row46_col9\" class=\"data row46 col9\" >0.769953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row47_col0\" class=\"data row47 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row47_col1\" class=\"data row47 col1\" >64</td>\n",
       "      <td id=\"T_c07ef_row47_col2\" class=\"data row47 col2\" >[3, 7]</td>\n",
       "      <td id=\"T_c07ef_row47_col3\" class=\"data row47 col3\" >9</td>\n",
       "      <td id=\"T_c07ef_row47_col4\" class=\"data row47 col4\" >0.351173</td>\n",
       "      <td id=\"T_c07ef_row47_col5\" class=\"data row47 col5\" >0.825367</td>\n",
       "      <td id=\"T_c07ef_row47_col6\" class=\"data row47 col6\" >0.459319</td>\n",
       "      <td id=\"T_c07ef_row47_col7\" class=\"data row47 col7\" >0.769701</td>\n",
       "      <td id=\"T_c07ef_row47_col8\" class=\"data row47 col8\" >0.460932</td>\n",
       "      <td id=\"T_c07ef_row47_col9\" class=\"data row47 col9\" >0.764192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row48_col0\" class=\"data row48 col0\" >256</td>\n",
       "      <td id=\"T_c07ef_row48_col1\" class=\"data row48 col1\" >64</td>\n",
       "      <td id=\"T_c07ef_row48_col2\" class=\"data row48 col2\" >[5, 3]</td>\n",
       "      <td id=\"T_c07ef_row48_col3\" class=\"data row48 col3\" >4</td>\n",
       "      <td id=\"T_c07ef_row48_col4\" class=\"data row48 col4\" >0.359596</td>\n",
       "      <td id=\"T_c07ef_row48_col5\" class=\"data row48 col5\" >0.826445</td>\n",
       "      <td id=\"T_c07ef_row48_col6\" class=\"data row48 col6\" >0.459697</td>\n",
       "      <td id=\"T_c07ef_row48_col7\" class=\"data row48 col7\" >0.764923</td>\n",
       "      <td id=\"T_c07ef_row48_col8\" class=\"data row48 col8\" >0.459242</td>\n",
       "      <td id=\"T_c07ef_row48_col9\" class=\"data row48 col9\" >0.765189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row49_col0\" class=\"data row49 col0\" >256</td>\n",
       "      <td id=\"T_c07ef_row49_col1\" class=\"data row49 col1\" >64</td>\n",
       "      <td id=\"T_c07ef_row49_col2\" class=\"data row49 col2\" >[3, 7]</td>\n",
       "      <td id=\"T_c07ef_row49_col3\" class=\"data row49 col3\" >3</td>\n",
       "      <td id=\"T_c07ef_row49_col4\" class=\"data row49 col4\" >0.417417</td>\n",
       "      <td id=\"T_c07ef_row49_col5\" class=\"data row49 col5\" >0.788134</td>\n",
       "      <td id=\"T_c07ef_row49_col6\" class=\"data row49 col6\" >0.461844</td>\n",
       "      <td id=\"T_c07ef_row49_col7\" class=\"data row49 col7\" >0.752982</td>\n",
       "      <td id=\"T_c07ef_row49_col8\" class=\"data row49 col8\" >0.460065</td>\n",
       "      <td id=\"T_c07ef_row49_col9\" class=\"data row49 col9\" >0.747597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row50_col0\" class=\"data row50 col0\" >512</td>\n",
       "      <td id=\"T_c07ef_row50_col1\" class=\"data row50 col1\" >64</td>\n",
       "      <td id=\"T_c07ef_row50_col2\" class=\"data row50 col2\" >[3, 5]</td>\n",
       "      <td id=\"T_c07ef_row50_col3\" class=\"data row50 col3\" >5</td>\n",
       "      <td id=\"T_c07ef_row50_col4\" class=\"data row50 col4\" >0.375207</td>\n",
       "      <td id=\"T_c07ef_row50_col5\" class=\"data row50 col5\" >0.809022</td>\n",
       "      <td id=\"T_c07ef_row50_col6\" class=\"data row50 col6\" >0.464191</td>\n",
       "      <td id=\"T_c07ef_row50_col7\" class=\"data row50 col7\" >0.762175</td>\n",
       "      <td id=\"T_c07ef_row50_col8\" class=\"data row50 col8\" >0.462286</td>\n",
       "      <td id=\"T_c07ef_row50_col9\" class=\"data row50 col9\" >0.767665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row51_col0\" class=\"data row51 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row51_col1\" class=\"data row51 col1\" >64</td>\n",
       "      <td id=\"T_c07ef_row51_col2\" class=\"data row51 col2\" >[3, 5]</td>\n",
       "      <td id=\"T_c07ef_row51_col3\" class=\"data row51 col3\" >11</td>\n",
       "      <td id=\"T_c07ef_row51_col4\" class=\"data row51 col4\" >0.302334</td>\n",
       "      <td id=\"T_c07ef_row51_col5\" class=\"data row51 col5\" >0.857287</td>\n",
       "      <td id=\"T_c07ef_row51_col6\" class=\"data row51 col6\" >0.464885</td>\n",
       "      <td id=\"T_c07ef_row51_col7\" class=\"data row51 col7\" >0.761199</td>\n",
       "      <td id=\"T_c07ef_row51_col8\" class=\"data row51 col8\" >0.460886</td>\n",
       "      <td id=\"T_c07ef_row51_col9\" class=\"data row51 col9\" >0.773570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row52_col0\" class=\"data row52 col0\" >512</td>\n",
       "      <td id=\"T_c07ef_row52_col1\" class=\"data row52 col1\" >64</td>\n",
       "      <td id=\"T_c07ef_row52_col2\" class=\"data row52 col2\" >[5, 3]</td>\n",
       "      <td id=\"T_c07ef_row52_col3\" class=\"data row52 col3\" >6</td>\n",
       "      <td id=\"T_c07ef_row52_col4\" class=\"data row52 col4\" >0.313576</td>\n",
       "      <td id=\"T_c07ef_row52_col5\" class=\"data row52 col5\" >0.849393</td>\n",
       "      <td id=\"T_c07ef_row52_col6\" class=\"data row52 col6\" >0.465861</td>\n",
       "      <td id=\"T_c07ef_row52_col7\" class=\"data row52 col7\" >0.761700</td>\n",
       "      <td id=\"T_c07ef_row52_col8\" class=\"data row52 col8\" >0.458515</td>\n",
       "      <td id=\"T_c07ef_row52_col9\" class=\"data row52 col9\" >0.772006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c07ef_row53_col0\" class=\"data row53 col0\" >1024</td>\n",
       "      <td id=\"T_c07ef_row53_col1\" class=\"data row53 col1\" >64</td>\n",
       "      <td id=\"T_c07ef_row53_col2\" class=\"data row53 col2\" >[5, 3]</td>\n",
       "      <td id=\"T_c07ef_row53_col3\" class=\"data row53 col3\" >10</td>\n",
       "      <td id=\"T_c07ef_row53_col4\" class=\"data row53 col4\" >0.290976</td>\n",
       "      <td id=\"T_c07ef_row53_col5\" class=\"data row53 col5\" >0.861778</td>\n",
       "      <td id=\"T_c07ef_row53_col6\" class=\"data row53 col6\" >0.466506</td>\n",
       "      <td id=\"T_c07ef_row53_col7\" class=\"data row53 col7\" >0.757068</td>\n",
       "      <td id=\"T_c07ef_row53_col8\" class=\"data row53 col8\" >0.463920</td>\n",
       "      <td id=\"T_c07ef_row53_col9\" class=\"data row53 col9\" >0.762301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14a653ca930>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to data frame and then output the results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_sorted_df = results_df.sort_values('Validation (Loss)')\n",
    "results_sorted_df.to_csv('results/grid_search_results.csv', index=False)\n",
    "results_sorted_df.style.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83efd0f5-a0bc-4aa0-bb37-b9c3dc1e8377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_688b8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_688b8_level0_col0\" class=\"col_heading level0 col0\" >Batch Size</th>\n",
       "      <th id=\"T_688b8_level0_col1\" class=\"col_heading level0 col1\" >Max Tokens</th>\n",
       "      <th id=\"T_688b8_level0_col2\" class=\"col_heading level0 col2\" >Filter Size</th>\n",
       "      <th id=\"T_688b8_level0_col3\" class=\"col_heading level0 col3\" >Epoch</th>\n",
       "      <th id=\"T_688b8_level0_col4\" class=\"col_heading level0 col4\" >Training (Loss)</th>\n",
       "      <th id=\"T_688b8_level0_col5\" class=\"col_heading level0 col5\" >Training (Accuracy)</th>\n",
       "      <th id=\"T_688b8_level0_col6\" class=\"col_heading level0 col6\" >Validation (Loss)</th>\n",
       "      <th id=\"T_688b8_level0_col7\" class=\"col_heading level0 col7\" >Validation (Accuracy)</th>\n",
       "      <th id=\"T_688b8_level0_col8\" class=\"col_heading level0 col8\" >Testing (Loss)</th>\n",
       "      <th id=\"T_688b8_level0_col9\" class=\"col_heading level0 col9\" >Testing (Accuracy)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_688b8_row0_col0\" class=\"data row0 col0\" >1024</td>\n",
       "      <td id=\"T_688b8_row0_col1\" class=\"data row0 col1\" >512</td>\n",
       "      <td id=\"T_688b8_row0_col2\" class=\"data row0 col2\" >[3, 7]</td>\n",
       "      <td id=\"T_688b8_row0_col3\" class=\"data row0 col3\" >12</td>\n",
       "      <td id=\"T_688b8_row0_col4\" class=\"data row0 col4\" >0.263356</td>\n",
       "      <td id=\"T_688b8_row0_col5\" class=\"data row0 col5\" >0.871315</td>\n",
       "      <td id=\"T_688b8_row0_col6\" class=\"data row0 col6\" >0.413981</td>\n",
       "      <td id=\"T_688b8_row0_col7\" class=\"data row0 col7\" >0.789345</td>\n",
       "      <td id=\"T_688b8_row0_col8\" class=\"data row0 col8\" >0.430199</td>\n",
       "      <td id=\"T_688b8_row0_col9\" class=\"data row0 col9\" >0.792425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14a0ed29640>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ouput the best result\n",
    "final_results_sorted_df = results_sorted_df.head(1)\n",
    "final_results_sorted_df.style.hide()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
